{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Connect to STK/ODTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python Libraries\n",
    "# !pip install \"C:\\Program Files\\AGI\\STK 12\\bin\\AgPythonAPI\\agi.stk12-{version}-py3-none-any.whl\"\n",
    "# !pip install opencv-python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import imageio\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import win32com.client as w32c\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from skimage.color import rgb2gray\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from skimage.feature import peak_local_max\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import Angle\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Import STK Libraries\n",
    "\n",
    "from agi.stk12.stkdesktop import STKDesktop\n",
    "from agi.stk12.stkobjects import *\n",
    "from agi.stk12.stkutil import *\n",
    "from agi.stk12.vgt import *\n",
    "from agi.stk12.utilities.colors import Color, Colors\n",
    "\n",
    "# Import functions from EOIRProcessesing.py\n",
    "from EOIRProcessingLib import *\n",
    "\n",
    "if not os.path.exists(\"Images\"):\n",
    "    os.makedirs(\"Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attatch to open instance of STK\n",
    "stk = STKDesktop.AttachToApplication()  # attach to exisiting instance of stk\n",
    "root = stk.Root\n",
    "root.Isolate()\n",
    "root.UnitPreferences.Item(\"DateFormat\").SetCurrentUnit(\"EpSec\")\n",
    "sc = root.CurrentScenario\n",
    "\n",
    "# Attach to exisiting instance of ODTK\n",
    "try:\n",
    "    #\n",
    "    app = w32c.GetActiveObject(\"ODTK7.Application\")\n",
    "    ODTK = app.Personality\n",
    "except:\n",
    "    print(\"Did not connect to ODTK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples and Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Considerations\n",
    "\n",
    "* Use a sensor type of Fixed or Fixed in Axes if you are updating the sensor pointing based on observations\n",
    "* Using updateSensorMethod = 'previousMeasurementDirection' requires azStart and elStart to be defined\n",
    "* If your satellite is maneuevering or changing attitude, you might want to use a frame other than the body frame\n",
    "* Depending on what type of sensor you are modeling, it may be beneficial to set constrains such as Sun exclusion angle, target must be lit, space only backgrounds, in STK and/or ODTK\n",
    "* If you plan on running ODTK ensure STK and ODTK are using the same force models.See: https://help.agi.com/ODTK/index.htm#../LinkedDocuments/astrodynamicsConsistency.pdf \n",
    "* Right now the measurements passed to ODTK are assumed to be spacebased and passed in the form of a .geosc. The file format supports non-spacedbased measurements (facility observations), but the code to write the .geosc file would need to be updated to support this, see the function RADECToMeasurementFileLine in EOIRProcessingLib.py \n",
    "* You may want to modify the file paths of where images/videos are saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up\n",
    "sensorPath = \"*/Satellite/LEO/Sensor/LEOLaunchTracker\"\n",
    "tstart = 0\n",
    "tstop = 120\n",
    "tstep = 2\n",
    "\n",
    "# Image Processing\n",
    "minSNR = 3\n",
    "percentofmax = 0.25\n",
    "method = \"localpeaks\"  # 'localpeaks','minSNR','percentofmax','kmeans'\n",
    "maxObjects = 1\n",
    "k = (\n",
    "    1 / 3\n",
    ")  # Common Values: 1/3(enhances dark spots), 1 (simply normalizes), and 2 (enhances bright spots)\n",
    "\n",
    "# Update Sensor Position\n",
    "updateSensorMethod = \"previousMeasurementDirection\"  # '' (this will skip updating), 'previousmeasurementdirection','odtk'\n",
    "azStart = -90\n",
    "elStart = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set Up\n",
    "# sensorPath = '*/Satellite/LEO/Sensor/LEODetector'\n",
    "# tstart  = 0\n",
    "# tstop = 500\n",
    "# tstep = 10\n",
    "\n",
    "# # Image Processing\n",
    "# minSNR = 3\n",
    "# percentofmax = 0.25\n",
    "# method = 'localpeaks' # 'localpeaks','minSNR','percentofmax','kmeans'\n",
    "# maxObjects = 1\n",
    "# k = 1/3 # Common Values: 1/3(enhances dark spots), 1 (simply normalizes), and 2 (enhances bright spots)\n",
    "# differenceImages = False # Only use for staring sensors\n",
    "\n",
    "\n",
    "# # Update Sensor Position\n",
    "# updateSensorMethod = '' # '' (this will skip updating), 'previousmeasurementdirection','odtk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set Up\n",
    "# sensorPath = '*/Aircraft/UAV/Sensor/HGVTracker'\n",
    "# tstart  = 1000\n",
    "# tstop = 1300\n",
    "# tstep = 5 # 10\n",
    "\n",
    "# # Image Processing\n",
    "# minSNR = 2.5\n",
    "# percentofmax = 0.25\n",
    "# method = 'localpeaks' # 'localpeaks','minSNR','percentofmax','kmeans'\n",
    "# maxObjects = 1\n",
    "# k = 1/3 # Common Values: 1/3(enhances dark spots), 1 (simply normalizes), and 2 (enhances bright spots)\n",
    "\n",
    "# # Update Sensor Position\n",
    "# updateSensorMethod = 'previousMeasurementDirection' # '' (this will skip updating), 'previousmeasurementdirection','odtk'\n",
    "# azStart = 170\n",
    "# elStart = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set Up\n",
    "# sensorPath = '*/Satellite/HEO/Sensor/HEOLaunch'\n",
    "# tstart  = 0\n",
    "# tstop = 40\n",
    "# tstep = 0.2\n",
    "\n",
    "# # Image Processing\n",
    "# minSNR = 5\n",
    "# percentofmax = 0.25\n",
    "# method = 'localpeaks' # 'localpeaks','minSNR','percentofmax','kmeans'\n",
    "# maxObjects = 1\n",
    "# k = 1/3 # Common Values: 1/3(enhances dark spots), 1 (simply normalizes), and 2 (enhances bright spots)\n",
    "# differenceImages = False # Only use for staring sensors\n",
    "# deltaTime = 3 # Use a multiple of the time step\n",
    "\n",
    "# # Update Sensor Position\n",
    "# updateSensorMethod = '' # '' (this will skip updating), 'previousmeasurementdirection','odtk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set Up, #Use the scal imagery\n",
    "# sensorPath = '*/Aircraft/UAV/Sensor/LaunchTracker'\n",
    "# tstart  = 0.1\n",
    "# tstop = 60.1\n",
    "# tstep = .5\n",
    "\n",
    "# # Image Processing\n",
    "# minSNR = 3\n",
    "# percentofmax = 0.25\n",
    "# method = 'localpeaks' # 'localpeaks','minSNR','percentofmax','kmeans'\n",
    "# maxObjects = 1\n",
    "# k = 1/3 # Common Values: 1/3(enhances dark spots), 1 (simply normalizes), and 2 (enhances bright spots)\n",
    "\n",
    "# # Update Sensor Position\n",
    "# updateSensorMethod = 'previousMeasurementDirection' # '' (this will skip updating), 'previousmeasurementdirection','odtk'\n",
    "# azStart = 100\n",
    "# elStart = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set Up, #Use the scal imagery\n",
    "# sensorPath = '*/Satellite/GEO/Sensor/Stare'\n",
    "# tstart  = 0\n",
    "# tstop = 500\n",
    "# tstep = 10\n",
    "# sensorPath = '*/Satellite/GEO/Sensor/StareHGV'\n",
    "# tstart  = 1000\n",
    "# tstop = 1400\n",
    "# tstep = 10\n",
    "\n",
    "# # Image Processing\n",
    "# minSNR = 3\n",
    "# percentofmax = 0.25\n",
    "# method = 'localpeaks' # 'localpeaks','minSNR','percentofmax','kmeans'\n",
    "# maxObjects = 1\n",
    "# k = 1/3 # Common Values: 1/3(enhances dark spots), 1 (simply normalizes), and 2 (enhances bright spots)\n",
    "\n",
    "# # Update Sensor Position\n",
    "# updateSensorMethod = '' # '' (this will skip updating), 'previousmeasurementdirection','odtk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set Up\n",
    "# sensorPath = '*/Satellite/RPO/Sensor/Detector'\n",
    "# tstart  = 4800\n",
    "# tstop = 12800\n",
    "# tstep = 60\n",
    "\n",
    "# # Image Processing\n",
    "# minSNR = 5\n",
    "# percentofmax = 0.25\n",
    "# method = 'localpeaks' # 'localpeaks','minSNR','percentofmax','kmeans'\n",
    "# maxObjects = 1\n",
    "# k = 1 # Common Values: 1/3(enhances dark spots), 1 (simply normalizes), and 2 (enhances bright spots)\n",
    "\n",
    "# # Update Sensor Position\n",
    "# updateSensorMethod = 'odtk'# '' (this will skip updating), 'previousmeasurementdirection','odtk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Inputs\n",
    "\n",
    "# Output/Runtime Settings\n",
    "writeVideo = False  # Combine the tagged images into a video\n",
    "realTimeRate = 5  # (tstop-tstart)/realTimeRate = videoLength assuming no frames are missing, how fast the final video should play relative to real time\n",
    "reuseFiles = True  # Reuse existing eoir images/text files if they already exist\n",
    "\n",
    "# Limit Observations\n",
    "useAccessConstraintsToLimitObs = (\n",
    "    False  # Limit imaging times to be within access intervals\n",
    ")\n",
    "targetPath = \"*/Satellite/TargetODTK\"  # Access object, usually the object you are trying to observe/detect\n",
    "\n",
    "# Plotting\n",
    "plotImage = True  # Show the tagged images\n",
    "\n",
    "# ODTK settings, Modify these as needed if you are running ODTK\n",
    "ODSatName = \"RPO\"  # Odtk satellite name with the sensor\n",
    "ODFilterName = \"Filter1\"  # Filter name\n",
    "ODTargetName = \"Target\"  # Object you are trying to perform OD on\n",
    "targetID = 1001  # Target tracking ID in ODTK\n",
    "sensorID = 1000  # Sensor tracking ID in ODTK\n",
    "RAstd = 0.00  # 1 standard deviation in arcSec, format is xx.xx, setting to 0 uses ODTK's value\n",
    "DECstd = 0.00  # 1 standard deviation in arcSec, format is xx.xx, setting to 0 uses ODTK's value\n",
    "usePixelSizeForStd = False  # overrides the RAstd and DECstd values based on pixel size\n",
    "visualizeOD = False  # Set to True if you want to see the filter run in STK as it goes\n",
    "\n",
    "\n",
    "# Look for differences in images instead of the image itself, Only use for staring sensors\n",
    "differenceImages = False\n",
    "deltaTime = tstep  # Time to difference images, use a multiple of the time step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Imaging Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get handles and setup for intiial config\n",
    "sensor = root.GetObjectFromPath(sensorPath)\n",
    "vectors = sensor.Vgt.Vectors\n",
    "sensorName = sensorPath.split(\"/\")[-1]\n",
    "\n",
    "if (\n",
    "    differenceImages == True\n",
    "):  # Differencing only works for staring images, don't update the sensor pointing\n",
    "    updateSensorMethod = \"\"\n",
    "\n",
    "# Use a sensor type of Fixed or Fixed in Axes if you are updating the sensor pointing\n",
    "if sensor.PointingType == AgESnPointing.eSnPtFixedAxes:\n",
    "    axes = sensor.Pointing.ReferenceAxes[:-5]\n",
    "else:\n",
    "    axes = \"/\".join(sensorPath.split(\"/\")[1:3]) + \" Body\"\n",
    "    print(\"Assuming Parent Body axes and the sensor pointing type is Fixed\")\n",
    "\n",
    "\n",
    "# Set up ODTK\n",
    "if updateSensorMethod.lower() == \"odtk\":\n",
    "    # Get ODTK handles\n",
    "    ODScenario = ODTK.Scenario(0)\n",
    "    ODSat = ODScenario.Satellite(ODSatName)\n",
    "    ODFilter = ODScenario.Filter(ODFilterName)\n",
    "    ODObject = ODScenario.Satellite(ODTargetName)\n",
    "    # Add measurement file\n",
    "    measurementFile = sensorName + \".geosc\"\n",
    "    open(measurementFile, \"w\").close()  # Clear RADecfile\n",
    "    measurementFiles = ODScenario.Measurements.Files\n",
    "    measurementFiles.clear()\n",
    "    newFile = measurementFiles.NewElem()\n",
    "    newFile.Filename = os.getcwd() + \"\\\\\" + measurementFile\n",
    "    measurementFiles.push_back(newFile)\n",
    "    ODScenario.Measurements.Files(0).Enabled = True\n",
    "    # Run filter with no Obs\n",
    "    ODFilter.ProcessControl.StopMode = \"TimeSpan\"\n",
    "    ODFilter.ProcessControl.TimeSpan = (tstop - tstart) / 3600\n",
    "    ODFilter.Go()\n",
    "    ODFilter.ProcessControl.StopMode = \"LastMeasurement\"\n",
    "    predictionTimeSpan = 3600  # sec\n",
    "    ODFilter.Output.STKEphemeris.Predict.TimeSpan = (\n",
    "        predictionTimeSpan / 60\n",
    "    )  # Convert to mins\n",
    "    ephemerisFile = ODFilter.Output.STKEphemeris.Files(0).FileName()\n",
    "\n",
    "    # Set up VGT\n",
    "    points = sensor.Vgt.Points\n",
    "    if not points.Contains(\"EstimatedTargetLocation\"):\n",
    "        point = points.Factory.Create(\n",
    "            \"EstimatedTargetLocation\",\n",
    "            \"Estimated Pointing Location\",\n",
    "            AgECrdnPointType.eCrdnPointTypeFile,\n",
    "        )\n",
    "        point.Filename = ephemerisFile\n",
    "    point = points.Item(\"EstimatedTargetLocation\")\n",
    "    if not vectors.Contains(\"PointingDirection\"):\n",
    "        vector = vectors.Factory.Create(\n",
    "            \"PointingDirection\",\n",
    "            \"Estimated Pointing Direction\",\n",
    "            AgECrdnVectorType.eCrdnVectorTypeDisplacement,\n",
    "        )\n",
    "        vector.Destination.SetPath(sensorPath[2:] + \" EstimatedTargetLocation\")\n",
    "\n",
    "    # Set up filter run visualization\n",
    "    if visualizeOD == True:\n",
    "        if sc.Children.Contains(\n",
    "            AgESTKObjectType.eSatellite, targetPath.split(\"/\")[-1] + \"Filter\"\n",
    "        ):\n",
    "            satVis = root.GetObjectFromPath(targetPath + \"Filter\")\n",
    "        else:\n",
    "            satVis = sc.Children.New(\n",
    "                AgESTKObjectType.eSatellite, targetPath.split(\"/\")[-1] + \"Filter\"\n",
    "            )\n",
    "        satVis.SetPropagatorType(AgEVePropagatorType.ePropagatorStkExternal)\n",
    "        satVis.Propagator.Filename = ephemerisFile\n",
    "        satVis.VO.Covariance.Attributes.IsVisible = True\n",
    "        satVis.VO.OrbitSystems.RemoveAll()\n",
    "        satVis.VO.OrbitSystems.InertialByWindow.IsVisible = False\n",
    "        satVis.VO.OrbitSystems.Add(targetPath.split(\"*/\")[-1] + \" RIC System\")\n",
    "\n",
    "\n",
    "# Set up measurement vector\n",
    "if not vectors.Contains(\"MeasurementDirection\"):\n",
    "    vectors.Factory.Create(\n",
    "        \"MeasurementDirection\",\n",
    "        \"Measurement Direction\",\n",
    "        AgECrdnVectorType.eCrdnVectorTypeFixedInAxes,\n",
    "    )\n",
    "vector = vectors.Item(\"MeasurementDirection\")\n",
    "vector.ReferenceAxes.SetPath(axes)\n",
    "\n",
    "# Update initial pointing\n",
    "if updateSensorMethod.lower() == \"previousmeasurementdirection\":\n",
    "    sensor.Pointing.Orientation.AssignAzEl(\n",
    "        azStart, elStart, AgEAzElAboutBoresight.eAzElAboutBoresightRotate\n",
    "    )\n",
    "\n",
    "# Get the access handle\n",
    "if useAccessConstraintsToLimitObs == True:\n",
    "    access = sensor.GetAccess(targetPath)\n",
    "\n",
    "# Get pixel size\n",
    "(\n",
    "    horizontalPixels,\n",
    "    verticalPixels,\n",
    "    horizontalAngle,\n",
    "    verticalAngle,\n",
    ") = getSensorFOVAndPixels(sensor)\n",
    "horizontalDegPerPixel = horizontalAngle / horizontalPixels\n",
    "verticalDegPerPixel = verticalAngle / verticalPixels\n",
    "horizontalCenter = horizontalPixels / 2 + 0.5\n",
    "verticalCenter = verticalPixels / 2 + 0.5\n",
    "# Update RA and Dec based on pixel size\n",
    "if usePixelSizeForStd == True:\n",
    "    RAstd = horizontalDegPerPixel * 3600\n",
    "    DECstd = (\n",
    "        verticalDegPerPixel * 3600\n",
    "    )  # Be careful if this exceeds 99 arc Seconds, should add a check, could also leave blank to use ODTK values\n",
    "    if RAstd >= 100 or DECstd >= 100:\n",
    "        print(\"Setting standard deviations to use ODTK values\")\n",
    "        RAstd = 00.0\n",
    "        DECstd = 00.0\n",
    "\n",
    "# Set up times and measurements\n",
    "times = np.arange(tstart, tstop, tstep)\n",
    "times = np.append(times, tstop).round(\n",
    "    3\n",
    ")  # round to 1/1000th of a sec get rid of numerical issues\n",
    "timesWithTaggedImages = []\n",
    "measurementsAzElErrors = []\n",
    "meaurementsAzEl = []\n",
    "sensorPointingHistory = []\n",
    "imageFolder = os.getcwd() + \"\\\\Images\"\n",
    "t1 = time.time()\n",
    "\n",
    "# Loop through time\n",
    "for t in times:\n",
    "    # Set Animation time\n",
    "    print(\"Time:\", t)\n",
    "    t = float(t)\n",
    "    root.CurrentTime = t\n",
    "\n",
    "    # If running ODTK, update sensor pointing to predicted target location\n",
    "    if updateSensorMethod.lower() == \"odtk\":\n",
    "        # Have to force a filereload, there may be a better way, or could switch between the copy to save a bit of time\n",
    "        shutil.copyfile(\n",
    "            ephemerisFile, ephemerisFile.split(\".\")[0] + \"Copy.e\"\n",
    "        )  # copy src to dst\n",
    "        point.Filename = ephemerisFile.split(\".\")[0] + \"Copy.e\"\n",
    "        point.Filename = ephemerisFile\n",
    "        if visualizeOD == True:\n",
    "            satVis.Propagator.Filename = ephemerisFile.split(\".\")[0] + \"Copy.e\"\n",
    "            satVis.Propagator.Filename = ephemerisFile\n",
    "            satVis.Propagator.Propagate()\n",
    "        _, az, el = getPointingDirection(sensor, t, t, tstep, axes=axes)\n",
    "        sensor.Pointing.Orientation.AssignAzEl(\n",
    "            az, el, AgEAzElAboutBoresight.eAzElAboutBoresightRotate\n",
    "        )\n",
    "        print(\"Pointing Update:\", az, el)\n",
    "        sensorPointingHistory.append((t, az, el))\n",
    "\n",
    "    # Limit imagine times to when the object has access, this will take into account pointing updates\n",
    "    if useAccessConstraintsToLimitObs == True:\n",
    "        access.SpecifyAccessTimePeriod(t, t)\n",
    "        access.ComputeAccess()\n",
    "        skipAccess = False if access.ComputedAccessIntervalTimes.Count != 0 else True\n",
    "    else:\n",
    "        skipAccess = False\n",
    "\n",
    "    # Image Processing and Tagging\n",
    "    if skipAccess == False:\n",
    "        # Construct file names\n",
    "        imageName = '\"{}\\\\{}Time{}.jpg\"'.format(\n",
    "            imageFolder, sensorName, str(t).replace(\".\", \"_\")\n",
    "        )\n",
    "        textName = '\"{}\\\\{}Time{}.txt\"'.format(\n",
    "            imageFolder, sensorName, str(t).replace(\".\", \"_\")\n",
    "        )\n",
    "\n",
    "        # Run EOIR\n",
    "        getEOIRImages(\n",
    "            root, sensorPath, imageName=\"\", textName=textName, reuseFiles=reuseFiles\n",
    "        )  # set imageName=imageName if you want EOIR to generate the image\n",
    "\n",
    "        # Image processing\n",
    "        data = np.loadtxt(textName.replace('\"', \"\"))  # Load EOIR Image\n",
    "        # Difference Images if needed\n",
    "        if differenceImages == True:\n",
    "            textNamePrevious = '\"{}\\\\{}Time{}.txt\"'.format(\n",
    "                imageFolder, sensorName, str(t - deltaTime).replace(\".\", \"_\")\n",
    "            )\n",
    "            if os.path.exists(textNamePrevious.replace('\"', \"\")):\n",
    "                dataPrevious = np.loadtxt(textNamePrevious.replace('\"', \"\"))\n",
    "                data = data - dataPrevious\n",
    "            else:\n",
    "                continue  # skip to the next iteration if not previous image exists\n",
    "        timesWithTaggedImages.append(\n",
    "            t\n",
    "        )  # Time where an image processing attempt was made\n",
    "        image = normalizeImage(data, k=k, convertToInt=False, plotImage=False)\n",
    "\n",
    "        # Get the object centers\n",
    "        maxSNR = getMaxSNR(image)\n",
    "        objectCenters = getObjectCenters(\n",
    "            image,\n",
    "            method=method,\n",
    "            minSNR=minSNR,\n",
    "            percentofmax=percentofmax,\n",
    "            maxObjects=maxObjects,\n",
    "        )\n",
    "        if len(objectCenters) > 0:\n",
    "            objectCenters, objectSNRS = sortBySNR(\n",
    "                image, objectCenters\n",
    "            )  # Puts highest SNR last\n",
    "        else:\n",
    "            objectSNRS = []\n",
    "        print(\"Object Centers:\", objectCenters)\n",
    "        print(\"Object SNRs:\", objectSNRS)\n",
    "\n",
    "        # Store Az El measurements\n",
    "        for objectCenter in objectCenters:\n",
    "            azError = (objectCenter[1] - horizontalCenter) * horizontalDegPerPixel\n",
    "            elError = (objectCenter[0] - verticalCenter) * verticalDegPerPixel\n",
    "            measurementsAzElErrors.append((t, azError, elError))\n",
    "\n",
    "        # Update pointing and measurements if an object is detected\n",
    "        if len(objectCenters) > 0:\n",
    "            print(\"Errors (deg): \", azError, elError)\n",
    "\n",
    "            # Obs Association: The image detection process can detect multiple objects and figuring out which obs corresponds to which object is non-trival. This is an area of future improvment, with Python or lettings ODTK/OAT help out\n",
    "            # Common issues: Mistags, missed observations/undetectable signals,false positives (find peaks which are not the actual object, stars, clouds, background clutter.) Be aware of this, better image processing or sensors could resolve this.\n",
    "            # For now the script assumes a very simple object association: the highest SNR is the specified target object and will use this for pointing updates\n",
    "\n",
    "            # Get current rotation matrix for sensor body frame to specified axes\n",
    "            timeRotationZYXs = computeSensorBodyToParentRotations(\n",
    "                sensor, t, t, tstep, axes=axes\n",
    "            )\n",
    "            # Can also compute true values aif desired\n",
    "            #         trueAzElError = computeTrueSensorAzElError(sensor,t,t,tstep,target=targetPath.split('/')[-1])\n",
    "\n",
    "            # Calculate target direction in axes from az el offsets in sensor image\n",
    "            azMeas, elMeas, targetVec = updatePointingDir(\n",
    "                measurementsAzElErrors[-1][1],\n",
    "                measurementsAzElErrors[-1][2],\n",
    "                timeRotationZYXs[0, :],\n",
    "            )\n",
    "            meaurementsAzEl.append((t, azMeas, elMeas))\n",
    "\n",
    "            # Update the measurement direction vector\n",
    "            vector.Direction.AssignXYZ(targetVec[0], targetVec[1], targetVec[2])\n",
    "\n",
    "            # Convert the measurement direction vector to RA and Dec measurements\n",
    "            if updateSensorMethod.lower() == \"odtk\":\n",
    "                _, ra, dec = getRADECMeasurements(\n",
    "                    sensor, t, t, tstep, useMeasurementDirection=True\n",
    "                )\n",
    "                with open(measurementFile, \"a+\") as f:\n",
    "                    line = RADECToMeasurementFileLine(\n",
    "                        root,\n",
    "                        t,\n",
    "                        ra,\n",
    "                        dec,\n",
    "                        targetID=1001,\n",
    "                        sensorID=1000,\n",
    "                        RAstd=RAstd,\n",
    "                        DECstd=DECstd,\n",
    "                    )\n",
    "                    f.write(line)\n",
    "                print(\"RA Dec:\", ra, dec)\n",
    "                ODFilter.Go()\n",
    "\n",
    "            if updateSensorMethod.lower() == \"previousmeasurementdirection\":\n",
    "                sensor.Pointing.Orientation.AssignAzEl(\n",
    "                    azMeas, elMeas, AgEAzElAboutBoresight.eAzElAboutBoresightRotate\n",
    "                )\n",
    "                sensorPointingHistory.append((t, azMeas, elMeas))\n",
    "                # Alternative approaches/future improvements: could estimate position and velocity, can do simple regression for velocity, could look at multiple images(over time and different sensors), could do missle model and kalman filter\n",
    "\n",
    "        # Plotting\n",
    "        if plotImage == True:\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            if differenceImages == True:\n",
    "                data = np.loadtxt(\n",
    "                    textName.replace('\"', \"\")\n",
    "                )  # reload data for saving the image\n",
    "                image = normalizeImage(data, k=k, convertToInt=False, plotImage=False)\n",
    "            plt.imshow(image)\n",
    "            plt.imshow(image, cmap=\"gray\")\n",
    "            if len(objectCenters) > 0:\n",
    "                plt.plot(\n",
    "                    objectCenters[:, 1],\n",
    "                    objectCenters[:, 0],\n",
    "                    \"ro\",\n",
    "                    markersize=12,\n",
    "                    markerfacecolor=\"none\",\n",
    "                )\n",
    "            plt.title(\"Time: \" + str(t))\n",
    "            plt.savefig(\n",
    "                imageName.replace('\"', \"\").split(\".\")[0] + \"Tagged.png\", dpi=500\n",
    "            )\n",
    "            plt.show()\n",
    "\n",
    "        # continue loop\n",
    "        print(\"RunTime: \", time.time() - t1)\n",
    "\n",
    "    else:\n",
    "        print(\"Skipped Time:\", t)  # No access\n",
    "\n",
    "\n",
    "# Create a history of sensor pointing\n",
    "writeSensorPointingFile(\n",
    "    sensorPointingHistory, fileName=\"{}SensorPointing.sp\".format(sensorName), axes=axes\n",
    ")\n",
    "print(\"Wrote \", \"{}SensorPointing.sp\".format(sensorName))\n",
    "\n",
    "# Create a video\n",
    "if writeVideo == True:\n",
    "    createVideo(\n",
    "        sensorName, timesWithTaggedImages, tstep, imageFolder, realTimeRate=realTimeRate\n",
    "    )\n",
    "    print(\"Wrote \", \"{}.mp4\".format(sensorName))\n",
    "print(time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "789px",
    "left": "1532px",
    "right": "20px",
    "top": "113px",
    "width": "368px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
